
---
layout: post
title: Sequential Monte Carlo
tags: statistics method
---

<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default"></script>



## Sequential Monte Carlo

### Motivation
Considering dynamic linear models, if each state follows Gaussian distribution and transformation is linear, then it is positive to derive an explicit expression to compute the evolcing sequence of posterior distribution. The recursion is well known as Kalman Filter. It is widely used in Hidden Markov Model.  

However, real data is very complicated typically involving elements of non-Gaussian, high dimensionality and nonlinearity. It is intractable to derive the exact posterior distribution. Therefore, many approximations schemes, such as extended Kalman filter, Gaussian sum approximation and grid-based filters, have been proposed. Fisrt two methods usually give poor results and the griod- based filter is too computational expensive especially for hign dimensions.

The ensemble Kalman filter is a popular data-driven approximation schemes. Hte key idea is to use sampling data for each state to approximate the true distribution.

#Sequential Monte Carlo# methods are a set of simulation-based methods for posterior distirubtion computation. It is widely used because it is very flexible and easy to implement and parallelisable.

### State Space Model
$P(x_0)$

$P(x_t|x_{t-1})$ for $t \leq 1$ (transition probability)

$P(y_t|x_t) for $t \leq 0$ (emission/observation probability)

Then filtering distribution ahd smoothing distribution are of insterest: $P(x_t|y_{0:t})$ and $P(x_t|y_{0:T})$.

### Bayesian Sampling
* For MCMC, there are two significant drawbacks: 
  - It is difficult to design a good proposal $q$ in Metroplis Hesting.
  - It is hard to reuse samples when we need to add a new data proint.
* For Important sampling, it has the same issues as the MCMC. But now that proposal distribution should be replaced by importance distribution.
* For Sequential importance sampling (Doucet et al. 2001; Cappe et al. 2007)
  - Review IS. For any distribution $q$ such that $\pi(x)>0 \rightarrow q(x)>0$ 
  $$\pi(x) = \frac{w(x)q(x)}{\int w(x)q(x) dx}$$
  where $w(x) = \frac{\pi(x)}{q(x)}$ and $q$ is called importance distribution and $w$ importance weight.
  
  - SIS consider the importance distribution 
  $$ \pi(x_{0:t}|y_{0:t}) = \pi(x_{0:t-1}|y_{0:t-1}) \pi(x_t|x_{0:t-1}, y_{0:t}) $$
  and the importace weight can then be evaluated recursively
  $$ w_t^ {(i)} \propto \frac{P(y_t|x_t^{(i)})P(x_t^{(i)}|x_{t-1}^{(i)})}{\pi(x_t^{(i)}|x_{0:t-1}^{(i)},y_{0:t})} $$
    + simulate $x_t^{(t)} \sim \pi(x_t|x_{0:t-1}^{(i)}, y_{0:t})$
    + update the weight $w^{(i)} for x_{0:t}^{(i)} based on $w_{t-1}^{(i)}$
  Then to emlimate weight degeneracy:
    + Eliminate particles with low importance weights
    + Multiple particles with high importance weights
  Resample a new trajectory by drawing N samples from $\hat{P}(x_{0:t}|y_{0:t}) = \frac{1}{N}\sum_{i=1}^N \delta_{x_{0:t}^{(i)}}(x_{0:t})w_t^{(i)}$. And according to the choice of proposal distribution, Bootstrap filter methdo appears.
* A generic SMC algorithm is proposed by Holenstein (2009).
* Other methods have Particle MCMC, Particle Metroplis Hastings Sampler, Particle Gibbs, Particle learning and so on.
  
  
* 
